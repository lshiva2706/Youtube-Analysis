{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "lnMLgnvpYMc8"
   },
   "outputs": [],
   "source": [
    "dir = 'C:/Users/mvemul2/Desktop/Youtube-Analysis/YT_Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "EldWrbU1YfG2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mvemul2\\AppData\\Local\\Temp\\ipykernel_6024\\4051890243.py:12: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import HTML,display\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections,os,json\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from IPython.core.display import HTML,display\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "simplefilter(action='ignore', category=UserWarning)\n",
    "simplefilter(action='ignore', category=RuntimeWarning)\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "eS6hCWO_Yg4a"
   },
   "outputs": [],
   "source": [
    "def set_css():\n",
    "  return display(HTML(\"\"\"<style>\n",
    "  #output-body {\n",
    "    display: flex;\n",
    "    align-items: center;\n",
    "    justify-content: center;\n",
    "    background-color:white;\n",
    "    color:black;\n",
    "    }\n",
    "  .output_text pre{\n",
    "    margin-right : 70px;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "    /* font-size: 10px; */\n",
    "  }\n",
    "\n",
    "}  </style>\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2oExDVsQYmta"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m5_yWwrODSFI"
   },
   "source": [
    "#Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S6vZNRi91vMs"
   },
   "source": [
    "##Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Z6p70r9Rot8Q"
   },
   "outputs": [],
   "source": [
    "def process_date_attributes(data):\n",
    "  data[\"publish_time\"] = pd.to_datetime(data[\"publish_time\"])\n",
    "  data[\"trending_date\"] = pd.to_datetime(data[\"trending_date\"],format=\"%y.%d.%m\")\n",
    "  data[\"trend_year\"]=data[\"trending_date\"].apply(lambda time:time.year)\n",
    "  data[\"trend_date\"] = data[\"trending_date\"].apply(lambda time: time.day)\n",
    "  data[\"trend_month\"]=data[\"trending_date\"].apply(lambda time:time.month)\n",
    "  data[\"publish_year\"]=data[\"publish_time\"].apply(lambda time:time.year)\n",
    "  data[\"publish_month\"]=data[\"publish_time\"].apply(lambda time:time.month)\n",
    "  data[\"publish_day\"]=data[\"publish_time\"].apply(lambda time:time.day)\n",
    "  data[\"publish_weekday\"]=data[\"publish_time\"].apply(lambda time:time.dayofweek)\n",
    "  data[\"publish_hour\"]=data[\"publish_time\"].apply(lambda time:time.hour)\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "m_VzmTLBBdn2"
   },
   "outputs": [],
   "source": [
    "def match_categories(x,dictionary): #function to get the categories\n",
    "    try:\n",
    "        return dictionary[str(x)]\n",
    "    except:\n",
    "        return \"Unknown\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-OkorSq10s1"
   },
   "source": [
    "##Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "3mpQIOPz10Ws"
   },
   "outputs": [],
   "source": [
    "def data_cleaning(data):\n",
    "  if data['description'].isnull().sum()>0:\n",
    "    data['description'] = data['description'].replace(np.nan,\"\") #Replacing the NaN values in the \"Description\" column with an empty string\n",
    "  data = data.sort_values('video_id').drop_duplicates(subset=['trending_date', 'title'], keep='last')\n",
    "  data = data.drop(columns=[\"publish_time\",\"category_id\"],axis=1)\n",
    "  return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f-bO_ZZl5wxq"
   },
   "source": [
    "##Loading the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "bNTt_yKxbf1O"
   },
   "outputs": [],
   "source": [
    "def load_data(file_path): \n",
    "    ch_file=file_path\n",
    "    Country_code = ch_file[0:2]\n",
    "    path=os.path.join(dir,ch_file)\n",
    "    input_df=pd.read_csv(path,encoding='utf-8')\n",
    "    title_dict={}\n",
    "    json_path=os.path.join(dir,(Country_code+str('_category_id.json')))\n",
    "    json_input_df=pd.read_json(json_path)\n",
    "    input_df['region']=Country_code\n",
    "    for dict_a in json_input_df['items']:\n",
    "        title_dict[dict_a['id']]=dict_a['snippet']['title'] \n",
    "    input_df = process_date_attributes(input_df) #Calling the function to process the date columns.\n",
    "    input_df['category']=input_df['category_id'].apply(match_categories,args=(title_dict,))\n",
    "    input_df = data_cleaning(input_df)\n",
    "    return input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "id": "vYhLfsK1fMDy",
    "outputId": "bb5fa477-6dfc-47e3-e206-0c99b7cb01df",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "  #output-body {\n",
       "    display: flex;\n",
       "    align-items: center;\n",
       "    justify-content: center;\n",
       "    background-color:white;\n",
       "    color:black;\n",
       "    }\n",
       "  .output_text pre{\n",
       "    margin-right : 70px;\n",
       "    color: black;\n",
       "    font-weight: bold;\n",
       "    /* font-size: 10px; */\n",
       "  }\n",
       "\n",
       "}  </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................................\n",
      "------Created CA DataFrame------\n",
      "------Created DE DataFrame------\n",
      "------Created FR DataFrame------\n",
      "------Created IN DataFrame------\n",
      "------Created US DataFrame------\n",
      "Processed all available Datasets\n",
      "................................\n",
      "tdf  is the cumulative DataFrame\n"
     ]
    }
   ],
   "source": [
    "set_css()\n",
    "con_list = []\n",
    "con_dict = {}\n",
    "t_list = []\n",
    "t_df = pd.DataFrame()\n",
    "for dirname, _, filenames in os.walk(dir):\n",
    "    print(\"................................\")\n",
    "    for paths in filenames:\n",
    "        if paths.lower().endswith(\".csv\"):\n",
    "          con_list.append(paths[0:2])\n",
    "          x = load_data(paths)\n",
    "          t_list.append(x)\n",
    "          x = x.drop(columns=['video_id','region'],axis=1)\n",
    "          globals()[str(paths[0:2])] = x\n",
    "          con_dict[str(paths[0:2])]=x\n",
    "          print(\"------Created\",paths[0:2],\"DataFrame------\")\n",
    "    print(\"Processed all available Datasets\")\n",
    "t_df = pd.concat(t_list,ignore_index=True)\n",
    "tdf = t_df\n",
    "tdf.name = \"The 6 Countries\"\n",
    "print(\"................................\")\n",
    "print(\"tdf  is the cumulative DataFrame\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "EauET5Zs2jGU"
   },
   "outputs": [],
   "source": [
    "def get_unique_categ(data):\n",
    "  cat_x = data['category'].unique()\n",
    "  cat_y = list(cat_x)\n",
    "  if \"Unknown\" in cat_y:\n",
    "    cat_y.remove('Unknown')\n",
    "  dictc = {}\n",
    "  for i in range(0,len(cat_y)):\n",
    "    dictc[i] = cat_y[i]\n",
    "  return dictc,cat_x\n",
    "# dict_cat,cat_x = get_unique_categ(tdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LF449RyLeq_H"
   },
   "source": [
    "##Filling the Missing Categories using Word Vectorisers and Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "id": "7qFRrQoCdfv6",
    "outputId": "e13b813c-322b-4850-de0e-fb3aeddea2b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CA 74\n",
      "DE 256\n",
      "FR 114\n",
      "IN 103\n",
      "US 0\n"
     ]
    }
   ],
   "source": [
    "for i,j in con_dict.items():\n",
    "  print(i,j[j.category==\"Unknown\"].value_counts().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "RZ7B9EhJmnzV"
   },
   "outputs": [],
   "source": [
    "gnb_model = MultinomialNB()\n",
    "rfc_model= RandomForestClassifier(n_estimators=20,verbose=False,n_jobs=-1)\n",
    "dtc_model = DecisionTreeClassifier()\n",
    "xgb_model=XGBClassifier()\n",
    "knn_model = KNeighborsClassifier(n_neighbors=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "5oSRq7VufgKs"
   },
   "outputs": [],
   "source": [
    "def create_model_data(data,nam):\n",
    "  mdf = data[[\"title\",\"category\"]]\n",
    "  mdf = mdf[mdf['category']!=\"Unknown\"].reset_index()\n",
    "  mdf['cid'] = 0\n",
    "  dict_a,_ = get_unique_categ(data)\n",
    "  for index,i in enumerate(mdf.category):\n",
    "    for j in dict_a.keys():\n",
    "      if dict_a[j]==i:\n",
    "        mdf.at[index,'cid'] = j\n",
    "  v = CountVectorizer()\n",
    "  words = v.fit_transform(mdf['title'].values)\n",
    "  cats = mdf.cid.values\n",
    "  filename = nam + '_vector.pkl'\n",
    "  pickle.dump(v, open(filename, 'wb'))\n",
    "  return words,cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "c_K6tIBnpOpF"
   },
   "outputs": [],
   "source": [
    "# def find_best_knn(X_train,y_train):\n",
    "#   from sklearn.model_selection import GridSearchCV\n",
    "#   knn2 = KNeighborsClassifier()\n",
    "#   param_grid = {'n_neighbors': np.arange(1,8)}\n",
    "#   knn_gscv = GridSearchCV(knn2, param_grid, cv=5)\n",
    "#   knn_gscv.fit(X_train, y_train)\n",
    "#   print(\"Optimal value for neighbors is->\",knn_gscv.best_params_,\"With accuracy->\",knn_gscv.best_score_)\n",
    "#   return list(knn_gscv.best_params_.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "LWm2mdm4xG7M"
   },
   "outputs": [],
   "source": [
    "def create_ensemble(data,nam):\n",
    "  print(\"-----------------Starting for\",nam,\"-----------------\")\n",
    "  X,y = create_model_data(data,nam)\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2)\n",
    "  dtc = dtc_model.fit(X,y)\n",
    "  gnb = gnb_model.fit(X,y)\n",
    "  xgb = xgb_model.fit(X,y)\n",
    "  rfc = rfc_model.fit(X,y)\n",
    "\n",
    "  knn = knn_model.fit(X_train,y_train)\n",
    "  print(\"----------------------------------------\",\"Implementing Ensemble model has started\",\"----------------------------------------\")\n",
    "  estimators=[('gnb_model', gnb), ('xgb_model', xgb), ('dtc_model',dtc), ('knn_model', knn), ('rfc_model', rfc)]\n",
    "  # ens_name = \"ensemble_\" + str(nam)\n",
    "  ens_name = VotingClassifier(estimators, voting='hard')\n",
    "  ens_name.fit(X,y)\n",
    "  acc_ens = ens_name.score(X_test, y_test)\n",
    "  print(\"----------------------------------------\",\"Implementing Ensemble model has finished\",\"----------------------------------------\")\n",
    "  print(\"\\nThe Ensemble Model for %s has achieved an accuracy of %.4f\" %(nam,acc_ens))\n",
    "  filename = nam + '_model.pkl'\n",
    "  pickle.dump(ens_name, open(filename, 'wb'))\n",
    "  return ens_name  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437
    },
    "id": "MecUqA4erg0m",
    "outputId": "2a46af49-730b-49ea-a833-cda004f0f86b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------Starting for CA -----------------\n",
      "---------------------------------------- Implementing Ensemble model has started ----------------------------------------\n",
      "---------------------------------------- Implementing Ensemble model has finished ----------------------------------------\n",
      "\n",
      "The Ensemble Model for CA has achieved an accuracy of 0.9966\n",
      "-----------------Starting for DE -----------------\n",
      "---------------------------------------- Implementing Ensemble model has started ----------------------------------------\n",
      "---------------------------------------- Implementing Ensemble model has finished ----------------------------------------\n",
      "\n",
      "The Ensemble Model for DE has achieved an accuracy of 0.9977\n",
      "-----------------Starting for FR -----------------\n",
      "---------------------------------------- Implementing Ensemble model has started ----------------------------------------\n",
      "---------------------------------------- Implementing Ensemble model has finished ----------------------------------------\n",
      "\n",
      "The Ensemble Model for FR has achieved an accuracy of 0.9959\n",
      "-----------------Starting for IN -----------------\n",
      "---------------------------------------- Implementing Ensemble model has started ----------------------------------------\n",
      "---------------------------------------- Implementing Ensemble model has finished ----------------------------------------\n",
      "\n",
      "The Ensemble Model for IN has achieved an accuracy of 0.9975\n"
     ]
    }
   ],
   "source": [
    "def perform_ensemble():\n",
    "  for i,j in con_dict.items():\n",
    "    if j[j.category==\"Unknown\"].value_counts().sum() > 0:\n",
    "      globals()[str(\"ensemble_\") + str(i)]  = create_ensemble(j,i)\n",
    "perform_ensemble()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w1Y_ytZWio4R"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "DA_category_prediction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
